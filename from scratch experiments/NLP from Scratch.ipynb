{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + FeedForward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v72t9_bx0iVh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ddb8IEhijJWt"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\ASUS\\\\Desktop\\\\arabic-empathetic-conversations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-Y5pmJFjZ2m",
    "outputId": "6e31b5fb-d9f7-44e2-fa0f-7602d281f29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عدد الصفوف الفارغة: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"عدد الصفوف الفارغة:\", df[df.isnull().all(axis=1)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IkSksodsjZ0Y"
   },
   "outputs": [],
   "source": [
    "df = df.drop('emotion', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kev1M1NBjZwD",
    "outputId": "a273417c-ccd7-4c2c-ed4c-114d7740b8a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أتذكر أنني ذهبت لمشاهدة الألعاب النارية مع أعز...</td>\n",
       "      <td>هل كان هذا صديقًا كنت تحبه أم مجرد أفضل صديق؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كان هذا أفضل صديق. اشتقت لها.</td>\n",
       "      <td>اين ذهبت؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لم نعد نتحدث.</td>\n",
       "      <td>هل كان هذا شيء حدث بسبب جدال؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام</td>\n",
       "      <td>أجل؟ أنا حقا لا أرى كيف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ألا تشعر بذلك .. إنه لأمر عجيب</td>\n",
       "      <td>أصطدم في الواقع بجدران فارغة في كثير من الأحيا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  أتذكر أنني ذهبت لمشاهدة الألعاب النارية مع أعز...   \n",
       "1                      كان هذا أفضل صديق. اشتقت لها.   \n",
       "2                                      لم نعد نتحدث.   \n",
       "3     أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام   \n",
       "4                     ألا تشعر بذلك .. إنه لأمر عجيب   \n",
       "\n",
       "                                              Answer  \n",
       "0      هل كان هذا صديقًا كنت تحبه أم مجرد أفضل صديق؟  \n",
       "1                                          اين ذهبت؟  \n",
       "2                      هل كان هذا شيء حدث بسبب جدال؟  \n",
       "3                            أجل؟ أنا حقا لا أرى كيف  \n",
       "4  أصطدم في الواقع بجدران فارغة في كثير من الأحيا...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\n",
    "    'context': 'Question',\n",
    "    'response': 'Answer',\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZOo7oY9QjZt7",
    "outputId": "d6a2f4d9-ef62-4900-b9e9-e870ac559ec5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أتذكر أنني ذهبت لمشاهدة الألعاب النارية مع أعز...</td>\n",
       "      <td>هل كان هذا صديقا كنت تحبه أم مجرد أفضل صديق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>كان هذا أفضل صديق اشتقت لها</td>\n",
       "      <td>اين ذهبت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لم نعد نتحدث</td>\n",
       "      <td>هل كان هذا شيء حدث بسبب جدال</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام</td>\n",
       "      <td>أجل أنا حقا لا أرى كيف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ألا تشعر بذلك  إنه لأمر عجيب</td>\n",
       "      <td>أصطدم في الواقع بجدران فارغة في كثير من الأحيا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  أتذكر أنني ذهبت لمشاهدة الألعاب النارية مع أعز...   \n",
       "1                        كان هذا أفضل صديق اشتقت لها   \n",
       "2                                       لم نعد نتحدث   \n",
       "3     أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام   \n",
       "4                       ألا تشعر بذلك  إنه لأمر عجيب   \n",
       "\n",
       "                                              Answer  \n",
       "0        هل كان هذا صديقا كنت تحبه أم مجرد أفضل صديق  \n",
       "1                                           اين ذهبت  \n",
       "2                       هل كان هذا شيء حدث بسبب جدال  \n",
       "3                             أجل أنا حقا لا أرى كيف  \n",
       "4  أصطدم في الواقع بجدران فارغة في كثير من الأحيا...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Removes punctuation, numbers, and dates from the text.\n",
    "  \"\"\"\n",
    "  text = re.sub(r'[^\\w\\s]', '', text) \n",
    "  text = re.sub(r'\\d+', '', text)  \n",
    "  text = re.sub(r'\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b', '', text)  \n",
    "  return text\n",
    "\n",
    "\n",
    "\n",
    "df['Question'] = df['Question'].astype(str).apply(clean_text)\n",
    "df['Answer'] = df['Answer'].astype(str).apply(clean_text)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwRUqjRCjZrr",
    "outputId": "12d2b8d0-1dfd-4d85-bf82-a369556cacc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5436\\2587305540.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['Question' , 'Answer']] = df[['Question' , 'Answer']].applymap(remove_tashkeel)\n"
     ]
    }
   ],
   "source": [
    "def remove_tashkeel(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    return re.sub(r'[\\u064B-\\u065F]', '', text)\n",
    "\n",
    "df[['Question' , 'Answer']] = df[['Question' , 'Answer']].applymap(remove_tashkeel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgeqHgDuj2Nk",
    "outputId": "ff607f20-e94e-41a9-a162-e781b55c376b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk --quiet\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TkY1owP0j1_s"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        stop_words = set(stopwords.words('arabic'))\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        return \" \".join(filtered_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6NF0_NOj18-",
    "outputId": "449f0db2-dafb-41ce-a4d1-cb04f0794632"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5436\\2400414305.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['Question', 'Answer']] = df[['Question', 'Answer']].applymap(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "df[['Question', 'Answer']] = df[['Question', 'Answer']].applymap(remove_stopwords)\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okCg9UC_j16q",
    "outputId": "a39c6a15-5476-4695-8cf5-1be6cf76eefb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_5436\\2287126913.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['Question', 'Answer']] = df[['Question', 'Answer']].applymap(remove_punctuation)\n"
     ]
    }
   ],
   "source": [
    "df[['Question', 'Answer']] = df[['Question', 'Answer']].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jg2khQz5kNaI"
   },
   "outputs": [],
   "source": [
    "def generate_response_candidates(df, num_negatives=2):\n",
    "    data = []\n",
    "    all_responses = df['Answer'].tolist()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['Question']\n",
    "        correct_response = row['Answer']\n",
    "\n",
    "        negatives = random.sample([r for r in all_responses if r != correct_response], num_negatives)\n",
    "        data.append((question, correct_response, 1))  \n",
    "        for neg in negatives:\n",
    "            data.append((question, neg, 0))  \n",
    "\n",
    "    return pd.DataFrame(data, columns=['Question', 'Answer', 'label'])\n",
    "\n",
    "pairs_df = generate_response_candidates(df, num_negatives=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Y6xsmUXnkNYd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "vectorizer.fit(pairs_df['Question'].tolist() + pairs_df['Answer'].tolist())\n",
    "\n",
    "def get_vector(text):\n",
    "    return vectorizer.transform([text]).toarray()[0]\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for _, row in pairs_df.iterrows():\n",
    "    q_vec = get_vector(row['Question'])\n",
    "    r_vec = get_vector(row['Answer'])\n",
    "    combined = np.concatenate([q_vec, r_vec])\n",
    "    X.append(combined)\n",
    "    y.append(row['label'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cPfQABPnkNVj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1237/1237 [==============================] - 13s 9ms/step - loss: 0.6422 - accuracy: 0.6657 - val_loss: 0.6432 - val_accuracy: 0.6632\n",
      "Epoch 2/10\n",
      "1237/1237 [==============================] - 9s 7ms/step - loss: 0.6351 - accuracy: 0.6676 - val_loss: 0.6466 - val_accuracy: 0.6632\n",
      "Epoch 3/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.6309 - accuracy: 0.6676 - val_loss: 0.6528 - val_accuracy: 0.6632\n",
      "Epoch 4/10\n",
      "1237/1237 [==============================] - 12s 9ms/step - loss: 0.6235 - accuracy: 0.6676 - val_loss: 0.6661 - val_accuracy: 0.6632\n",
      "Epoch 5/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.6077 - accuracy: 0.6718 - val_loss: 0.6927 - val_accuracy: 0.6494\n",
      "Epoch 6/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.5798 - accuracy: 0.6934 - val_loss: 0.7306 - val_accuracy: 0.6145\n",
      "Epoch 7/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.5359 - accuracy: 0.7313 - val_loss: 0.7825 - val_accuracy: 0.5878\n",
      "Epoch 8/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.4778 - accuracy: 0.7755 - val_loss: 0.8394 - val_accuracy: 0.5576\n",
      "Epoch 9/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.4079 - accuracy: 0.8194 - val_loss: 0.9084 - val_accuracy: 0.5541\n",
      "Epoch 10/10\n",
      "1237/1237 [==============================] - 10s 8ms/step - loss: 0.3399 - accuracy: 0.8576 - val_loss: 0.9843 - val_accuracy: 0.5411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uB2asEGw1SrM"
   },
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder & LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "questions = df['Question'].tolist()\n",
    "answers = df['Answer'].tolist()\n",
    "\n",
    "\n",
    "answers_input = ['<start> ' + a for a in answers]\n",
    "answers_target = [a + ' <end>' for a in answers]\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(questions + answers_input + answers_target)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "q_seq = tokenizer.texts_to_sequences(questions)\n",
    "a_input_seq = tokenizer.texts_to_sequences(answers_input)\n",
    "a_target_seq = tokenizer.texts_to_sequences(answers_target)\n",
    "\n",
    "\n",
    "max_len = 20\n",
    "q_seq = pad_sequences(q_seq, maxlen=max_len, padding='post')\n",
    "a_input_seq = pad_sequences(a_input_seq, maxlen=max_len, padding='post')\n",
    "a_target_seq = pad_sequences(a_target_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len,))\n",
    "enc_emb = Embedding(vocab_size, 256, mask_zero=True)(encoder_inputs)\n",
    "_, h, c = LSTM(256, return_state=True)(enc_emb)\n",
    "encoder_states = [h, c]\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(max_len,))\n",
    "dec_emb = Embedding(vocab_size, 256, mask_zero=True)(decoder_inputs)\n",
    "dec_lstm = LSTM(256, return_sequences=True)(dec_emb, initial_state=encoder_states)\n",
    "dec_dense = Dense(vocab_size, activation='softmax')(dec_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "516/516 [==============================] - 280s 524ms/step - loss: 2.5306 - accuracy: 0.1503 - val_loss: 2.5812 - val_accuracy: 0.1502\n",
      "Epoch 2/10\n",
      "516/516 [==============================] - 741s 1s/step - loss: 2.1731 - accuracy: 0.1797 - val_loss: 2.4664 - val_accuracy: 0.1776\n",
      "Epoch 4/10\n",
      "516/516 [==============================] - 261s 506ms/step - loss: 2.0744 - accuracy: 0.1896 - val_loss: 2.4457 - val_accuracy: 0.1833\n",
      "Epoch 5/10\n",
      "516/516 [==============================] - 275s 533ms/step - loss: 1.9801 - accuracy: 0.1998 - val_loss: 2.4397 - val_accuracy: 0.1916\n",
      "Epoch 6/10\n",
      "516/516 [==============================] - 265s 515ms/step - loss: 1.8864 - accuracy: 0.2109 - val_loss: 2.4496 - val_accuracy: 0.1946\n",
      "Epoch 7/10\n",
      "516/516 [==============================] - 473s 918ms/step - loss: 1.7927 - accuracy: 0.2221 - val_loss: 2.4662 - val_accuracy: 0.1957\n",
      "Epoch 8/10\n",
      "516/516 [==============================] - 258s 501ms/step - loss: 1.6981 - accuracy: 0.2357 - val_loss: 2.4884 - val_accuracy: 0.1951\n",
      "Epoch 9/10\n",
      "516/516 [==============================] - 263s 510ms/step - loss: 1.6015 - accuracy: 0.2511 - val_loss: 2.5343 - val_accuracy: 0.1942\n",
      "Epoch 10/10\n",
      "516/516 [==============================] - 271s 524ms/step - loss: 1.5038 - accuracy: 0.2708 - val_loss: 2.5754 - val_accuracy: 0.1937\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], dec_dense)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([q_seq, a_input_seq], a_target_seq,\n",
    "                    batch_size=64, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text):\n",
    "    \n",
    "    seq = tokenizer.texts_to_sequences([input_text])\n",
    "    seq = pad_sequences(seq, maxlen=max_len, padding='post')  \n",
    "\n",
    "    target_seq = np.zeros((1, max_len))\n",
    "    target_seq[0, 0] = tokenizer.word_index.get('<start>', 1)\n",
    "\n",
    "    response = []\n",
    "\n",
    "    for i in range(1, max_len):\n",
    "        preds = model.predict([seq, target_seq], verbose=0)\n",
    "        pred_id = np.argmax(preds[0, i - 1])\n",
    "\n",
    "        if pred_id == 0 or pred_id == tokenizer.word_index.get('<end>', 2):\n",
    "            break\n",
    "\n",
    "        word = tokenizer.index_word.get(pred_id, '')\n",
    "        response.append(word)\n",
    "        target_seq[0, i] = pred_id\n",
    "\n",
    "    return ' '.join(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " سؤال: أشعر بالحزن\n",
      " رد النموذج: حدث\n",
      "\n",
      " سؤال: أنا قلق بشأن مستقبلي\n",
      " رد النموذج: \n",
      "\n",
      " سؤال: لقد نجحت في الامتحان\n",
      " رد النموذج: يجب تكون فخورا جدا\n",
      "\n",
      " سؤال: صديقي تخلى عني\n",
      " رد النموذج: بتحسين الروك مرة أخرى\n"
     ]
    }
   ],
   "source": [
    "test_questions = [\n",
    "    \"أشعر بالحزن\",\n",
    "    \"أنا قلق بشأن مستقبلي\",\n",
    "    \"لقد نجحت في الامتحان\",\n",
    "    \"صديقي تخلى عني\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\n سؤال: {q}\")\n",
    "    print(f\" رد النموذج: {generate_response(q)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Word2Vec & Attention Mechanism & LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 20, 256)      10795776    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 20, 256)      10795776    ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  [(None, 20, 256),    525312      ['embedding_4[0][0]']            \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  [(None, 20, 256),    525312      ['embedding_5[0][0]',            \n",
      "                                 (None, 256),                     'lstm_4[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_4[0][2]']                 \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 20, 20)       0           ['lstm_5[0][0]',                 \n",
      "                                                                  'lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 20, 20)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 20, 256)      0           ['activation[0][0]',             \n",
      "                                                                  'lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 20, 512)      0           ['dot_1[0][0]',                  \n",
      "                                                                  'lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 20, 256)     131328      ['concatenate[0][0]']            \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 20, 42171)   10837947    ['time_distributed[0][0]']       \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,611,451\n",
      "Trainable params: 33,611,451\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, TimeDistributed, dot, Activation\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len,))\n",
    "encoder_embedding = Embedding(vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(max_len,))\n",
    "decoder_embedding = Embedding(vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "# Attention Mechanism\n",
    "attention = dot([decoder_outputs, encoder_outputs], axes=[2, 2]) \n",
    "attention = Activation('softmax')(attention)\n",
    "context = dot([attention, encoder_outputs], axes=[2,1]) \n",
    "\n",
    "\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "\n",
    "output = TimeDistributed(Dense(256, activation=\"relu\"))(decoder_combined_context)\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(output)\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "max_len = 20\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['Question'].tolist() + df['Answer'].tolist())\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "q_seq = tokenizer.texts_to_sequences(df['Question'].tolist())\n",
    "a_seq = tokenizer.texts_to_sequences(df['Answer'].tolist())\n",
    "\n",
    "\n",
    "sos_token = tokenizer.word_index.get('بداية', 1) \n",
    "eos_token = tokenizer.word_index.get('نهاية', 2)\n",
    "\n",
    "decoder_input_seq = [[sos_token] + seq for seq in a_seq]\n",
    "decoder_target_seq = [seq + [eos_token] for seq in a_seq]\n",
    "\n",
    "\n",
    "encoder_input_data = pad_sequences(q_seq, maxlen=max_len, padding='post')\n",
    "decoder_input_data = pad_sequences(decoder_input_seq, maxlen=max_len, padding='post')\n",
    "decoder_target_data = pad_sequences(decoder_target_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "516/516 [==============================] - 379s 728ms/step - loss: 2.6617 - accuracy: 0.7042 - val_loss: 2.5770 - val_accuracy: 0.6899\n",
      "Epoch 2/5\n",
      "516/516 [==============================] - 392s 759ms/step - loss: 2.2963 - accuracy: 0.7160 - val_loss: 2.5299 - val_accuracy: 0.6947\n",
      "Epoch 3/5\n",
      "516/516 [==============================] - 390s 755ms/step - loss: 2.2006 - accuracy: 0.7194 - val_loss: 2.4963 - val_accuracy: 0.6970\n",
      "Epoch 4/5\n",
      "516/516 [==============================] - 395s 766ms/step - loss: 2.1098 - accuracy: 0.7222 - val_loss: 2.4658 - val_accuracy: 0.7005\n",
      "Epoch 5/5\n",
      "516/516 [==============================] - 392s 760ms/step - loss: 2.0182 - accuracy: 0.7250 - val_loss: 2.4576 - val_accuracy: 0.7028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b40dec6740>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_target_data.reshape(decoder_target_data.shape[0], decoder_target_data.shape[1], 1),\n",
    "          batch_size=64, epochs=5, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder & Embedding & Pad_Sequences & LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, dot, Activation\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:\\\\Users\\\\ASUS\\\\Desktop\\\\arabic-empathetic-conversations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={\"context\": \"Question\", \"response\": \"Answer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^؀-ۿ\\s]', '', str(text))  \n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2['Question'] = df2['Question'].apply(clean_text).apply(remove_tashkeel)\n",
    "df2['Answer'] = df2['Answer'].apply(clean_text).apply(remove_tashkeel)\n",
    "df2['Emotion'] = df2['emotion'].apply(clean_text).apply(remove_tashkeel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Input'] = \"العاطفة: \" + df2['Emotion'] + \"، السؤال: \" + df2['Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df2['Input'].tolist()\n",
    "target_texts = df2['Answer'].tolist()\n",
    "\n",
    "sos_token = 'بداية'\n",
    "eos_token = 'نهاية'\n",
    "target_texts_input = [sos_token + ' ' + t for t in target_texts]\n",
    "target_texts_output = [t + ' ' + eos_token for t in target_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_texts + target_texts_input + target_texts_output)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_len = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_seq = tokenizer.texts_to_sequences(input_texts)\n",
    "decoder_input_seq = tokenizer.texts_to_sequences(target_texts_input)\n",
    "decoder_target_seq = tokenizer.texts_to_sequences(target_texts_output)\n",
    "\n",
    "encoder_input_seq = pad_sequences(encoder_input_seq, maxlen=max_len, padding='post')\n",
    "decoder_input_seq = pad_sequences(decoder_input_seq, maxlen=max_len, padding='post')\n",
    "decoder_target_seq = pad_sequences(decoder_target_seq, maxlen=max_len, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len,))\n",
    "enc_emb = Embedding(vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_len,))\n",
    "dec_emb = Embedding(vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = dot([decoder_outputs, encoder_outputs], axes=[2, 2])\n",
    "attention = Activation('softmax')(attention)\n",
    "context = dot([attention, encoder_outputs], axes=[2, 1])\n",
    "\n",
    "decoder_combined_context = Concatenate(axis=-1)([context, decoder_outputs])\n",
    "\n",
    "output = TimeDistributed(Dense(256, activation=\"relu\"))(decoder_combined_context)\n",
    "decoder_dense = TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(output)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "516/516 [==============================] - 405s 779ms/step - loss: 3.4892 - accuracy: 0.5539 - val_loss: 3.2901 - val_accuracy: 0.5455\n",
      "Epoch 2/10\n",
      "516/516 [==============================] - 398s 771ms/step - loss: 2.9045 - accuracy: 0.5858 - val_loss: 3.0551 - val_accuracy: 0.5713\n",
      "Epoch 3/10\n",
      "516/516 [==============================] - 386s 747ms/step - loss: 2.6449 - accuracy: 0.6054 - val_loss: 2.9102 - val_accuracy: 0.5864\n",
      "Epoch 4/10\n",
      "516/516 [==============================] - 398s 772ms/step - loss: 2.4495 - accuracy: 0.6179 - val_loss: 2.8378 - val_accuracy: 0.5921\n",
      "Epoch 5/10\n",
      "516/516 [==============================] - 393s 762ms/step - loss: 2.2913 - accuracy: 0.6266 - val_loss: 2.8096 - val_accuracy: 0.5969\n",
      "Epoch 6/10\n",
      "516/516 [==============================] - 409s 793ms/step - loss: 2.1511 - accuracy: 0.6344 - val_loss: 2.8205 - val_accuracy: 0.5964\n",
      "Epoch 7/10\n",
      "516/516 [==============================] - 396s 768ms/step - loss: 2.0167 - accuracy: 0.6423 - val_loss: 2.8474 - val_accuracy: 0.5960\n",
      "Epoch 8/10\n",
      "516/516 [==============================] - 524s 1s/step - loss: 1.8829 - accuracy: 0.6513 - val_loss: 2.9044 - val_accuracy: 0.5952\n",
      "Epoch 9/10\n",
      "516/516 [==============================] - 403s 781ms/step - loss: 1.7511 - accuracy: 0.6632 - val_loss: 2.9582 - val_accuracy: 0.5904\n",
      "Epoch 10/10\n",
      "516/516 [==============================] - 407s 788ms/step - loss: 1.6223 - accuracy: 0.6796 - val_loss: 3.0360 - val_accuracy: 0.5879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b418cd51e0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data = np.expand_dims(decoder_target_seq, -1)\n",
    "\n",
    "model.fit([encoder_input_seq, decoder_input_seq], decoder_target_data,\n",
    "          batch_size=64, epochs=10, validation_split=0.1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Experiment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf tokenizer & sequnetial & Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\ASUS\\\\Desktop\\\\arabic-empathetic-conversations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['context', 'response'])\n",
    "df = df.rename(columns={'context': 'Question', 'response': 'Answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\u064B-\\u065F]', '', text) \n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    return text\n",
    "\n",
    "df['Question'] = df['Question'].astype(str).apply(clean_text)\n",
    "df['Answer'] = df['Answer'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['Question'] = df['Question'].apply(remove_stopwords)\n",
    "df['Answer'] = df['Answer'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_candidates(df, num_negatives=2):\n",
    "    data = []\n",
    "    all_responses = df['Answer'].tolist()\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['Question']\n",
    "        correct = row['Answer']\n",
    "        data.append((question, correct, 1))\n",
    "\n",
    "    negatives = random.sample([r for r in all_responses if r != correct], num_negatives)\n",
    "    for neg in negatives:\n",
    "        data.append((question, neg, 0))\n",
    "\n",
    "    return pd.DataFrame(data, columns=['Question', 'Answer', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = generate_response_candidates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectorizer.fit(pairs_df['Question'].tolist() + pairs_df['Answer'].tolist())\n",
    "\n",
    "\n",
    "q_vecs = vectorizer.transform(pairs_df['Question'].tolist())\n",
    "a_vecs = vectorizer.transform(pairs_df['Answer'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_sparse = hstack([q_vecs, a_vecs])\n",
    "X = X_sparse.toarray()\n",
    "y = np.array(pairs_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "Dense(512, activation='relu', input_shape=(X.shape[1],)),\n",
    "Dropout(0.4),\n",
    "Dense(256, activation='relu'),\n",
    "Dropout(0.2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "413/413 [==============================] - 2s 3ms/step - loss: 0.1209 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "413/413 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 8.2648e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "413/413 [==============================] - 1s 3ms/step - loss: 9.1915e-04 - accuracy: 1.0000 - val_loss: 3.7573e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "413/413 [==============================] - 1s 3ms/step - loss: 6.7706e-04 - accuracy: 1.0000 - val_loss: 2.2080e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "413/413 [==============================] - 1s 3ms/step - loss: 5.1156e-04 - accuracy: 1.0000 - val_loss: 1.4118e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b15d184d90>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder & Tokenizer & LSTM & Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('C:\\\\Users\\\\ASUS\\\\Desktop\\\\arabic-empathetic-conversations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>أتذكر أنني ذهبت لمشاهدة الألعاب النارية مع أعز...</td>\n",
       "      <td>هل كان هذا صديقًا كنت تحبه أم مجرد أفضل صديق؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>كان هذا أفضل صديق. اشتقت لها.</td>\n",
       "      <td>اين ذهبت؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>لم نعد نتحدث.</td>\n",
       "      <td>هل كان هذا شيء حدث بسبب جدال؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afraid</td>\n",
       "      <td>أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام</td>\n",
       "      <td>أجل؟ أنا حقا لا أرى كيف</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afraid</td>\n",
       "      <td>ألا تشعر بذلك .. إنه لأمر عجيب</td>\n",
       "      <td>أصطدم في الواقع بجدران فارغة في كثير من الأحيا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                            context  \\\n",
       "0  sentimental  أتذكر أنني ذهبت لمشاهدة الألعاب النارية مع أعز...   \n",
       "1  sentimental                      كان هذا أفضل صديق. اشتقت لها.   \n",
       "2  sentimental                                      لم نعد نتحدث.   \n",
       "3       afraid     أشعر وكأنني ضرب على جدار فارغ عندما أرى الظلام   \n",
       "4       afraid                     ألا تشعر بذلك .. إنه لأمر عجيب   \n",
       "\n",
       "                                            response  \n",
       "0      هل كان هذا صديقًا كنت تحبه أم مجرد أفضل صديق؟  \n",
       "1                                          اين ذهبت؟  \n",
       "2                      هل كان هذا شيء حدث بسبب جدال؟  \n",
       "3                            أجل؟ أنا حقا لا أرى كيف  \n",
       "4  أصطدم في الواقع بجدران فارغة في كثير من الأحيا...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dropna(subset=[\"emotion\", \"context\", \"response\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_text'] = df['emotion'] + \" : \" + df['context']\n",
    "df['target_text'] = \"<sos> \" + df['response'] + \" <eos>\"\n",
    "\n",
    "input_texts = df['input_text'].tolist()\n",
    "target_texts = df['target_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "input_padded = pad_sequences(input_sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "target_tokenizer.fit_on_texts(target_texts)\n",
    "target_sequences = target_tokenizer.texts_to_sequences(target_texts)\n",
    "target_padded = pad_sequences(target_sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(input_tokenizer.word_index) + 1\n",
    "num_decoder_tokens = len(target_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = input_padded.shape[1]\n",
    "max_decoder_seq_length = target_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = input_padded\n",
    "decoder_input_data = target_padded[:, :-1]\n",
    "decoder_target_data = target_padded[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_in, y_test_in, y_train_out, y_test_out = train_test_split(\n",
    "encoder_input_data, decoder_input_data, decoder_target_data,\n",
    "test_size=0.2,\n",
    "random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 826s 2s/step - loss: 1.1504 - accuracy: 0.8879 - val_loss: 0.7869 - val_accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243521012d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_out = np.expand_dims(y_train_out, -1)\n",
    "y_test_out = np.expand_dims(y_test_out, -1)\n",
    "\n",
    "model.fit([X_train, y_train_in], y_train_out,\n",
    "validation_data=([X_test, y_test_in], y_test_out),\n",
    "batch_size=64,\n",
    "epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
